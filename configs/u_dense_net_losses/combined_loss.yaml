SoftDice&CrossEntropy: 
  epochs: 30
  log_dir: results
  batch_size: 256
  path_row_config:
    train: [0, 4000000, 10]
    validation: [1, 4000000, 100]
    test: [4000000, 5000000, 500]
  model_config:
    lr: 0.001
    input_shape: [64, 64, 2]
    num_db: 7
    convs_per_db: 2
    growth_rate: 16
    num_channels: 16
  loss_config:
    name: combined_loss
    loss_configs:
      - name: soft_dice
      - name: cross_entropy
        beta: 0.75
        balanced: True
    weights: [5.0, 0.05]
