{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4add64-0e3d-49e1-b833-2532eed35c1b",
   "metadata": {},
   "source": [
    "# Project updates\n",
    "In this notebook, we present the updates from the experiment results of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5f136-bce2-4fcc-bbc1-9dcb034230c7",
   "metadata": {},
   "source": [
    "## Data structure\n",
    "The environments used in our project are simple `64x64` grid-worlds with different obstacles configurations.\n",
    "Our objective is to achieve obstacle-free path planning from a `start` position to a `goal` position.\n",
    "In total, we have **5000** different worlds (obstacle configurations) and for each configuration, we have **1000** different \n",
    "start and goal position pairs. So our dataset consists of **5,000,000** samples where \n",
    "the **1000** consecutive samples belong to a particular world.\n",
    "\n",
    "<img src=\"../assets/images/environment_components.png\" alt=\"Example Samples\"/>  \n",
    "\n",
    "As seen in the example samples above, our dataset consists of following data:\n",
    "1. **Obstacle image:** `64x64` 2D image representing the obstacles of the world.\n",
    "2. **Start image:** `64x64` 2D image representing the start position in the world.\n",
    "3. **End image:** `64x64` 2D image representing the end position in the world.\n",
    "4. **Path image:** `64x64` 2D image representing the path between the start and end positions in the world.\n",
    "5. **Path vector**: `22x2` 2D vector representation of the `path image`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e401c885-546c-41f9-92d7-2d27ca9ef6ac",
   "metadata": {},
   "source": [
    "## Supervised Learning approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87f4a9-94a8-45f2-abec-51843325e0fb",
   "metadata": {},
   "source": [
    "### Image-to-Image approach  \n",
    "**Inputs:** \n",
    "- `64x64x2` 3D image with the given images stacked:  \n",
    "  - `obstacle` image\n",
    "  - `start` and `end` images concatenated\n",
    "\n",
    "**Outputs:** \n",
    "- Path prediction as an `64x64x1` image\n",
    "\n",
    "**Network architecture:**  \n",
    "<img src=\"../assets/images/u_densenet_arch.png\" alt=\"U-DenseNet-Architecture\" width=\"1100\"/>  \n",
    "\n",
    "The hyperparameters for the above U-DenseNet architecture are:\n",
    "- Number of dense blocks: 5\n",
    "- Convolution blocks per dense blocK: 2\n",
    "- Growth rate: 16\n",
    "- Number of channels: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322f1e4-f55d-42d7-bd1b-6cdafbd9d00b",
   "metadata": {},
   "source": [
    "**Loss functions:**  \n",
    "\n",
    "In our project, we experimented with the following loss functions:  \n",
    "- **Cross entropy losses:**  \n",
    "\n",
    "  **1. Cross Entropy (CE):**     \n",
    "$$ L(Y, \\hat{Y}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{w=1}^{W} \\sum_{h=1}^{H} (Y_{iwh} log(\\hat{Y}_{iwh}) - (1-Y_{iwh}) log(1-\\hat{Y}_{iwh}))$$  \n",
    "  where  \n",
    "  $Y$ and $\\hat{Y}$ are the set of the *true* and *predicted* path images respectively and the images in both set are normalized within the range $[0, 1]$.  \n",
    "  \n",
    "  **2. Weighted Cross Entropy (WCE):**   \n",
    "  In the Weighted Cross Entropy loss, the positive examples are weighted by the coefficient $\\beta \\gt 0.0$.\n",
    "$$ L(Y, \\hat{Y}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{w=1}^{W} \\sum_{h=1}^{H} (\\underline{\\beta} Y_{iwh} log(\\hat{Y}_{iwh}) - (1-Y_{iwh}) log(1-\\hat{Y}_{iwh}))$$\n",
    "  \n",
    "  **3. Balanced Cross Entropy (BCE):**   \n",
    "  In the Balanced Cross Entropy (BCE) loss, both the positive and negative examples are weighted by the coefficient $\\beta \\gt 0.0$.\n",
    "$$ L(Y, \\hat{Y}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{w=1}^{W} \\sum_{h=1}^{H} (\\underline{\\beta} Y_{iwh} log(\\hat{Y}_{iwh}) - \\underline{(1-\\beta)} (1-Y_{iwh}) log(1-\\hat{Y}_{iwh}))$$\n",
    "  \n",
    "  **4. Focal:**  \n",
    "  In the Focal loss, the positive and negative examples are weighted even further by the coefficients $\\beta \\gt 0.0$ and $\\gamma \\geq 0.0$.\n",
    "$$ L(Y, \\hat{Y}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{w=1}^{W} \\sum_{h=1}^{H} (\\beta \\underline{(1-\\hat{Y}_{iwh})^{\\gamma}} Y_{iwh} log(\\hat{Y}_{iwh}) - (1-\\beta) \\underline{{\\hat{Y}_{iwh}}^{\\gamma}} (1-Y_{iwh}) log(1-\\hat{Y}_{iwh}))$$  \n",
    "  \n",
    "- **Overlap losses:**  \n",
    "\n",
    "  **1. Soft Dice (SD):**  \n",
    "$$ L(Y, \\hat{Y}) = 1 - \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\frac{\\sum_{w=1}^{W} \\sum_{h=1}^{H} 2 Y_{iwh} \\hat{Y}_{iwh}}{\\sum_{w=1}^{W} \\sum_{h=1}^{H} \\left({Y_{iwh}}^2 + {\\hat{Y}_{iwh}}^2\\right)}\\right)$$   \n",
    "  \n",
    "  **2. Tversky:**   \n",
    "  The Tversky loss is the generalized version of the Dice loss as it introduces the weight coefficient $\\beta \\gt 0.0$.\n",
    "$$ L(Y, \\hat{Y}) = 1 - \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\frac{\\sum_{w=1}^{W} \\sum_{h=1}^{H} 2 Y_{iwh} \\hat{Y}_{iwh}}{\\sum_{w=1}^{W} \\sum_{h=1}^{H} \\left(Y_{iwh} \\hat{Y}_{iwh} + \\beta (1-Y_{iwh}) \\hat{Y}_{iwh} + (1-\\beta) Y_{iwh} (1-\\hat{Y}_{iwh})\\right)}\\right)$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0819608-b71a-4da7-a3de-56980008ae7c",
   "metadata": {},
   "source": [
    "**Results:**  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
